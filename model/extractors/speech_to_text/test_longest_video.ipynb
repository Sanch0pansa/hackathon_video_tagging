{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STT model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from moviepy.editor import VideoFileClip\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "import os\n",
    "import wave\n",
    "\n",
    "class SpeechToTextFeatureExtractor:\n",
    "    def __init__(self, embedding_model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\", vosk_model_path=\"path/to/vosk/russian/model\"):\n",
    "        # Embedding model (changed to multilingual model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(embedding_model_name, cache_dir=\"./cache\")\n",
    "        self.model = AutoModel.from_pretrained(embedding_model_name, cache_dir=\"./cache\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        # Vosk setup (use Russian model)\n",
    "        self.vosk_model = Model(vosk_model_path)\n",
    "\n",
    "    def extract_audio(self, video_path):\n",
    "        # Extract audio from video\n",
    "        video = VideoFileClip(video_path)\n",
    "        audio = video.audio\n",
    "        audio_path = \"temp_audio.wav\"\n",
    "        audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
    "        return audio_path\n",
    "\n",
    "    def audio_to_text(self, audio_path):\n",
    "        # Convert audio to text using Vosk\n",
    "        wf = wave.open(audio_path, \"rb\")\n",
    "        rec = KaldiRecognizer(self.vosk_model, wf.getframerate())\n",
    "\n",
    "        text = \"\"\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = json.loads(rec.Result())\n",
    "                text += result.get(\"text\", \"\") + \" \"\n",
    "\n",
    "        final_result = json.loads(rec.FinalResult())\n",
    "        text += final_result.get(\"text\", \"\")\n",
    "        return text.strip()\n",
    "\n",
    "    def get_embeddings(self, text):\n",
    "        # Get embeddings from text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\",\n",
    "                                padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        return embeddings\n",
    "\n",
    "    def extract_features(self, video_path):\n",
    "        # Extract features from video\n",
    "        audio_path = self.extract_audio(video_path)\n",
    "        text = self.audio_to_text(audio_path)\n",
    "        embeddings = self.get_embeddings(text)\n",
    "\n",
    "        # Clean up temporary audio file\n",
    "        os.remove(audio_path)\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import wave\n",
    "import json\n",
    "from vosk import KaldiRecognizer  # Add this import\n",
    "\n",
    "\n",
    "# Путь к русской модели Vosk\n",
    "vosk_model_path = \"/home/glooma/Code/Python/ML/Hakatons/hackathon_video_tagging/model/extractors/speech_to_text/vosk-model-small-ru-0.22\"\n",
    "\n",
    "# Проверка существования модели\n",
    "if not os.path.exists(vosk_model_path):\n",
    "    print(f\"Модель не найдена по пути: {vosk_model_path}\")\n",
    "    print(\"Пожалуйста, скачайте модель с https://alphacephei.com/vosk/models\")\n",
    "    print(\"и распакуйте ее в указанную директорию.\")\n",
    "    raise Exception(\"Модель Vosk не найдена\")\n",
    "\n",
    "# Create an instance of the extractor\n",
    "extractor = SpeechToTextFeatureExtractor(vosk_model_path=vosk_model_path)\n",
    "\n",
    "# Path to the test video\n",
    "# short video\n",
    "# test_video_path = \"/home/glooma/Code/Python/ML/Hakatons/train_dataset_tag_video/videos/1e0a5151efc26a3a8e038e132f6b80f4.mp4\"\n",
    "# long video\n",
    "test_video_path = \"/home/glooma/Code/Python/ML/Hakatons/train_dataset_tag_video/videos/0a148a3aa95e76ced2d993525badc986.mp4\"\n",
    "\n",
    "print(f\"Обработка видео: {test_video_path}\")\n",
    "\n",
    "# Extract audio\n",
    "audio_path = extractor.extract_audio(test_video_path)\n",
    "\n",
    "# Convert audio to text with progress bar\n",
    "wf = wave.open(audio_path, \"rb\")\n",
    "rec = KaldiRecognizer(extractor.vosk_model, wf.getframerate())  # Changed this line\n",
    "\n",
    "text = \"\"\n",
    "total_frames = wf.getnframes()\n",
    "chunk_size = 4000\n",
    "progress_bar = tqdm(total=total_frames, unit='фреймы', desc=\"Обработка аудио\")\n",
    "\n",
    "while True:\n",
    "    data = wf.readframes(chunk_size)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if rec.AcceptWaveform(data):\n",
    "        result = json.loads(rec.Result())\n",
    "        text += result.get(\"text\", \"\") + \" \"\n",
    "    progress_bar.update(len(data))\n",
    "\n",
    "final_result = json.loads(rec.FinalResult())\n",
    "text += final_result.get(\"text\", \"\")\n",
    "text = text.strip()\n",
    "\n",
    "progress_bar.close()\n",
    "print(f\"Транскрибированный текст: {text[:100]}...\")  # Вывод первых 100 символов\n",
    "\n",
    "# Get embeddings from the transcribed text\n",
    "embeddings = extractor.get_embeddings(text)\n",
    "print(f\"Форма эмбеддингов: {embeddings.shape}\")\n",
    "print(f\"Первые несколько значений эмбеддингов: {embeddings[0][:5]}\")\n",
    "\n",
    "# Clean up temporary files\n",
    "if os.path.exists(audio_path):\n",
    "    os.remove(audio_path)\n",
    "    print(f\"Временный аудиофайл удален: {audio_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
    "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
    "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
    "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
    "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /home/glooma/Code/Python/ML/Hakatons/hackathon_video_tagging/model/extractors/speech_to_text/vosk-model-small-ru-0.22/ivector/final.ie\n",
    "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
    "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
    "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from /home/glooma/Code/Python/ML/Hakatons/hackathon_video_tagging/model/extractors/speech_to_text/vosk-model-small-ru-0.22/graph/HCLr.fst /home/glooma/Code/Python/ML/Hakatons/hackathon_video_tagging/model/extractors/speech_to_text/vosk-model-small-ru-0.22/graph/Gr.fst\n",
    "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /home/glooma/Code/Python/ML/Hakatons/hackathon_video_tagging/model/extractors/speech_to_text/vosk-model-small-ru-0.22/graph/phones/word_boundary.int\n",
    "\n",
    "Обработка видео: /home/glooma/Code/Python/ML/Hakatons/train_dataset_tag_video/videos/0a148a3aa95e76ced2d993525badc986.mp4\n",
    "\n",
    "MoviePy - Writing audio in temp_audio.wav\n",
    "                                                                          \n",
    "MoviePy - Done.\n",
    "\n",
    "Обработка аудио: 870710400фреймы [29:06, 498652.70фреймы/s]  \n",
    "\n",
    "Транскрибированный текст: джой босса счету     стиль  не ещё как сумму свыше семьдесят лет аш свяжется          вот с с все чт...\n",
    "\n",
    "Форма эмбеддингов: torch.Size([1, 384])\n",
    "\n",
    "Первые несколько значений эмбеддингов: tensor([ 0.2839,  0.2753,  0.3234, -0.0230, -0.4369])\n",
    "\n",
    "Временный аудиофайл удален: temp_audio.wav\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
