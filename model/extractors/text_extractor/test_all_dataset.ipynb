{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Model BERT text to embeddings\n",
    "class TextFeatureExtractor:\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name, cache_dir=\"./cache\")\n",
    "        self.model = BertModel.from_pretrained(model_name, output_hidden_states=True, cache_dir=\"./cache\")\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(device)\n",
    "    \n",
    "    def extract_features(self, text: str) -> torch.Tensor:\n",
    "        # Tokenize input text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # Extract embeddings from the layer\n",
    "        embeddings = outputs.hidden_states[-2]\n",
    "\n",
    "        # Average embeddings of all tokens\n",
    "        sentence_embedding = torch.mean(embeddings, dim=1)\n",
    "        \n",
    "        return sentence_embedding\n",
    "\n",
    "    def cosine_similarity(self, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.nn.functional.cosine_similarity(a, b, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [07:41<00:00,  2.27it/s]\n",
      "Comparing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [00:31<00:00, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar pair:\n",
      "Video IDs: ('0ea016128113476c741eba66ecbb5f0a', 'fe8ac2d7f57582ac5665692813d76efa')\n",
      "Similarity: 1.000000238418579\n",
      "Texts:\n",
      "1: Ð Ð¾Ð¼Ð°Ð½ Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð°Ñ€Ñ‚Ð¸ÑÑ‚ Black STAR SLAME Ñ‡ÑƒÑ‚ÑŒ Ð½Ðµ ÑƒÑ‚Ð¾Ð½ÑƒÐ»Ð¸ - Ð’ Ð½Ð¾Ð²Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ ÑˆÐ¾Ñƒ Â«Ð¡Ð¿Ð¾Ñ€Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÂ» Ð Ð¾Ð¼Ð° Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ SLAME Ð¿Ð¾Ð´ Ð¿Ñ€Ð¸ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ÐºÑ€Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ñ€Ð¸Ð·Ñ‘Ñ€ÐºÐ¸ Ñ‡ÐµÐ¼Ð¿Ð¸Ð¾Ð½Ð°Ñ‚Ð¾Ð² Ð¼Ð¸Ñ€Ð° Ð±ÑƒÐ´ÑƒÑ‚ ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð²Ð¾Ð´Ñƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð»Ð°Ð²Ð°Ñ‚ÑŒ, ÐºÐ°Ðº Ð¿Ñ€Ð¾Ñ„Ð¸. Ð¡ÑƒÑ…Ð¸Ð¼ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð¸ÐºÑ‚Ð¾ Ð½Ðµ ÑƒÐ¹Ð´ÐµÑ‚, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑÐ°Ð¼Ð¸!\n",
      "2: Ð Ð¾Ð¼Ð°Ð½ Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð°Ñ€Ñ‚Ð¸ÑÑ‚ Black STAR SLAME Ñ‡ÑƒÑ‚ÑŒ Ð½Ðµ ÑƒÑ‚Ð¾Ð½ÑƒÐ»Ð¸ - Ð’ Ð½Ð¾Ð²Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ ÑˆÐ¾Ñƒ Â«Ð¡Ð¿Ð¾Ñ€Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÂ» Ð Ð¾Ð¼Ð° Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ SLAME Ð¿Ð¾Ð´ Ð¿Ñ€Ð¸ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ÐºÑ€Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ñ€Ð¸Ð·Ñ‘Ñ€ÐºÐ¸ Ñ‡ÐµÐ¼Ð¿Ð¸Ð¾Ð½Ð°Ñ‚Ð¾Ð² Ð¼Ð¸Ñ€Ð° Ð±ÑƒÐ´ÑƒÑ‚ ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð²Ð¾Ð´Ñƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð»Ð°Ð²Ð°Ñ‚ÑŒ, ÐºÐ°Ðº Ð¿Ñ€Ð¾Ñ„Ð¸. Ð¡ÑƒÑ…Ð¸Ð¼ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð¸ÐºÑ‚Ð¾ Ð½Ðµ ÑƒÐ¹Ð´ÐµÑ‚, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑÐ°Ð¼Ð¸!\n",
      "\n",
      "Least similar pair:\n",
      "Video IDs: ('809cf37aa35541e9c82d710ae3881b4d', '24dbccf1b42bb1498de96586c17d4957')\n",
      "Similarity: 0.393150269985199\n",
      "Texts:\n",
      "1: ÐœÐ°Ð»Ð°Ð¹Ð·Ð¸Ñ. Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚ Ð¾Ñ‚Ð´Ñ‹Ñ…? - Ð’ ÑÑ‚Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ Ð¡Ð°ÑˆÑƒ Ð’ÐµÐ»Ð¸ÐºÐ¾Ð»ÐµÐ¿Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¸ Ñ€ÑƒÑˆÐ¸Ñ‚ÑŒ ÑÑ‚ÐµÑ€ÐµÐ¾Ñ‚Ð¸Ð¿Ñ‹ Ð² ÐœÐ°Ð»Ð°Ð¹Ð·Ð¸ÑŽ. Ð¢Ð°Ð¼ Ð¡Ð°ÑˆÐ°: ÐÐµÐ¿Ñ€Ð¸Ð»Ð¸Ñ‡Ð½Ð¾ Ð¼Ð½Ð¾Ð³Ð¾ ÐµÑÑ‚, Ð½Ð¾ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÑ‚Ð¾Ð¼Ñƒ Ð¾Ð¿Ñ€Ð°Ð²Ð´Ð°Ð½Ð¸Ðµ. Ð Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ ÑÐµÐºÑ€ÐµÑ‚ Ð¿ÐµÑ€ÐµÑƒÐ»ÐºÐ° Ð»ÑŽÐ±Ð¾Ð²Ð½Ð¸Ñ† Ð² Ð³Ð¾Ñ€Ð¾Ð´Ðµ Ð˜Ð¿Ð¾. Ð‘Ð¾Ð¸Ñ‚ÑÑ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸ Ñ ÐºÑ€Ð¾ÐºÐ¾Ð´Ð¸Ð»Ð°Ð¼Ð¸. Ð¡Ñ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑÑ Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð°ÑÑ‚Ð½Ð¾Ð³Ð¾ Ñ‚Ð°Ð½Ñ†Ð° Ð² ÑÐµÐºÑ€ÐµÑ‚Ð½Ð¾Ð¼ Ð±Ð°Ñ€Ðµ ÐšÑƒÐ°Ð»Ð°-Ð›ÑƒÐ¼Ð¿ÑƒÑ€Ð°. Ð—Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑÑ Ñ Ð‘Ñ€ÑŽÑÐ¾Ð¼ Ð›Ð¸ Ð¸ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÑ‚ Ð¿ÐµÑ‰ÐµÑ€Ñƒ Ð¢ÐµÐ¼Ð¿ÑƒÑ€ÑƒÐ½Ð³. Ð˜ Ð¾Ñ‡ÐµÐ½ÑŒ, Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ÑÑ.  Ð—Ð° Ð·Ð½Ð°ÐºÐ¾Ð¼ÑÑ‚Ð²Ð¾ ÑÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¾Ð¹ ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð›ÑŽÐ±Ð¾Ð²Ð¸ (@lyuba_expat) Ð¸ ÐœÐ°Ñ€Ð¸Ð¸ (@travelmusha) Ð¾Ñ‚ Ð²ÑÐµÐ¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ðŸ™‚  Ð—Ð° Ð¿Ñ€Ð¸ÐºÐ¾Ð»Ñ‹ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð²Ñ‹Ð¿ÑƒÑÐºÐ° ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð¾Ð±ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°Ð¼.  #Ð¼Ð°Ð»Ð°Ð¹Ð·Ð¸Ñ #ÐºÑƒÐ°Ð»Ð°Ð»ÑƒÐ¼Ð¿ÑƒÑ€ #Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²Ð¸Ñ #ÑÐºÐ¾Ð»ÑŒÐºÐ¾ÑÑ‚Ð¾Ð¸Ñ‚Ð¾Ñ‚Ð´Ñ‹Ñ…\n",
      "2: Baikal Mile 2019 - International Festival of speed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming TextFeatureExtractor is already defined and imported\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/home/glooma/Code/Python/ML/Hakatons/train_dataset_tag_video/baseline/train_data_categories.csv')\n",
    "\n",
    "extractor = TextFeatureExtractor()\n",
    "\n",
    "# Dictionary to store embeddings\n",
    "embeddings = {}\n",
    "\n",
    "# Process each row\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing videos\"):\n",
    "    video_id = row['video_id']\n",
    "    title = row['title']\n",
    "    description = row['description']\n",
    "    \n",
    "    # Combine title and description\n",
    "    text = f\"{title} {description}\"\n",
    "    \n",
    "    # Get embedding\n",
    "    embedding = extractor.extract_features(text)\n",
    "    \n",
    "    # Store embedding\n",
    "    embeddings[video_id] = embedding\n",
    "\n",
    "# Find most and least similar pairs\n",
    "max_similarity = -1\n",
    "min_similarity = 2  # Cosine similarity is always between -1 and 1\n",
    "most_similar_pair = None\n",
    "least_similar_pair = None\n",
    "\n",
    "for id1, emb1 in tqdm(embeddings.items(), desc=\"Comparing embeddings\"):\n",
    "    for id2, emb2 in embeddings.items():\n",
    "        if id1 != id2:\n",
    "            similarity = extractor.cosine_similarity(emb1, emb2).item()\n",
    "            \n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar_pair = (id1, id2)\n",
    "            \n",
    "            if similarity < min_similarity:\n",
    "                min_similarity = similarity\n",
    "                least_similar_pair = (id1, id2)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nMost similar pair:\")\n",
    "print(f\"Video IDs: {most_similar_pair}\")\n",
    "print(f\"Similarity: {max_similarity}\")\n",
    "print(\"Texts:\")\n",
    "print(f\"1: {df[df['video_id'] == most_similar_pair[0]]['title'].values[0]} - {df[df['video_id'] == most_similar_pair[0]]['description'].values[0]}\")\n",
    "print(f\"2: {df[df['video_id'] == most_similar_pair[1]]['title'].values[0]} - {df[df['video_id'] == most_similar_pair[1]]['description'].values[0]}\")\n",
    "\n",
    "print(\"\\nLeast similar pair:\")\n",
    "print(f\"Video IDs: {least_similar_pair}\")\n",
    "print(f\"Similarity: {min_similarity}\")\n",
    "print(\"Texts:\")\n",
    "print(f\"1: {df[df['video_id'] == least_similar_pair[0]]['title'].values[0]} - {df[df['video_id'] == least_similar_pair[0]]['description'].values[0]}\")\n",
    "print(f\"2: {df[df['video_id'] == least_similar_pair[1]]['title'].values[0]} - {df[df['video_id'] == least_similar_pair[1]]['description'].values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [07:41<00:00,  2.27it/s]\n",
    "Comparing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [00:31<00:00, 33.50it/s]\n",
    "\n",
    "Most similar pair:\n",
    "\n",
    "Video IDs: ('0ea016128113476c741eba66ecbb5f0a', 'fe8ac2d7f57582ac5665692813d76efa')\n",
    "\n",
    "Similarity: 1.000000238418579\n",
    "\n",
    "Texts:\n",
    "\n",
    "1: Ð Ð¾Ð¼Ð°Ð½ Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð°Ñ€Ñ‚Ð¸ÑÑ‚ Black STAR SLAME Ñ‡ÑƒÑ‚ÑŒ Ð½Ðµ ÑƒÑ‚Ð¾Ð½ÑƒÐ»Ð¸ - Ð’ Ð½Ð¾Ð²Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ ÑˆÐ¾Ñƒ Â«Ð¡Ð¿Ð¾Ñ€Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÂ» Ð Ð¾Ð¼Ð° Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ SLAME Ð¿Ð¾Ð´ Ð¿Ñ€Ð¸ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ÐºÑ€Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ñ€Ð¸Ð·Ñ‘Ñ€ÐºÐ¸ Ñ‡ÐµÐ¼Ð¿Ð¸Ð¾Ð½Ð°Ñ‚Ð¾Ð² Ð¼Ð¸Ñ€Ð° Ð±ÑƒÐ´ÑƒÑ‚ ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð²Ð¾Ð´Ñƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð»Ð°Ð²Ð°Ñ‚ÑŒ, ÐºÐ°Ðº Ð¿Ñ€Ð¾Ñ„Ð¸. Ð¡ÑƒÑ…Ð¸Ð¼ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð¸ÐºÑ‚Ð¾ Ð½Ðµ ÑƒÐ¹Ð´ÐµÑ‚, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑÐ°Ð¼Ð¸!\n",
    "\n",
    "2: Ð Ð¾Ð¼Ð°Ð½ Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð°Ñ€Ñ‚Ð¸ÑÑ‚ Black STAR SLAME Ñ‡ÑƒÑ‚ÑŒ Ð½Ðµ ÑƒÑ‚Ð¾Ð½ÑƒÐ»Ð¸ - Ð’ Ð½Ð¾Ð²Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ ÑˆÐ¾Ñƒ Â«Ð¡Ð¿Ð¾Ñ€Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÂ» Ð Ð¾Ð¼Ð° Ð®Ð½ÑƒÑÐ¾Ð² Ð¸ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ‹Ð¹ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒ SLAME Ð¿Ð¾Ð´ Ð¿Ñ€Ð¸ÑÐ¼Ð¾Ñ‚Ñ€Ð¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ÐºÑ€Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ñ€Ð¸Ð·Ñ‘Ñ€ÐºÐ¸ Ñ‡ÐµÐ¼Ð¿Ð¸Ð¾Ð½Ð°Ñ‚Ð¾Ð² Ð¼Ð¸Ñ€Ð° Ð±ÑƒÐ´ÑƒÑ‚ ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐµ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð²Ð¾Ð´Ñƒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð»Ð°Ð²Ð°Ñ‚ÑŒ, ÐºÐ°Ðº Ð¿Ñ€Ð¾Ñ„Ð¸. Ð¡ÑƒÑ…Ð¸Ð¼ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð¸ÐºÑ‚Ð¾ Ð½Ðµ ÑƒÐ¹Ð´ÐµÑ‚, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ ÑÐ°Ð¼Ð¸!\n",
    "\n",
    "Least similar pair:\n",
    "\n",
    "Video IDs: ('809cf37aa35541e9c82d710ae3881b4d', '24dbccf1b42bb1498de96586c17d4957')\n",
    "\n",
    "Similarity: 0.393150269985199\n",
    "\n",
    "Texts:\n",
    "\n",
    "1: ÐœÐ°Ð»Ð°Ð¹Ð·Ð¸Ñ. Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚ Ð¾Ñ‚Ð´Ñ‹Ñ…? - Ð’ ÑÑ‚Ð¾Ð¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ Ð¡Ð°ÑˆÑƒ Ð’ÐµÐ»Ð¸ÐºÐ¾Ð»ÐµÐ¿Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¸ Ñ€ÑƒÑˆÐ¸Ñ‚ÑŒ ÑÑ‚ÐµÑ€ÐµÐ¾Ñ‚Ð¸Ð¿Ñ‹ Ð² ÐœÐ°Ð»Ð°Ð¹Ð·Ð¸ÑŽ. Ð¢Ð°Ð¼ Ð¡Ð°ÑˆÐ°: ÐÐµÐ¿Ñ€Ð¸Ð»Ð¸Ñ‡Ð½Ð¾ Ð¼Ð½Ð¾Ð³Ð¾ ÐµÑÑ‚, Ð½Ð¾ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÑ‚Ð¾Ð¼Ñƒ Ð¾Ð¿Ñ€Ð°Ð²Ð´Ð°Ð½Ð¸Ðµ. Ð Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ ÑÐµÐºÑ€ÐµÑ‚ Ð¿ÐµÑ€ÐµÑƒÐ»ÐºÐ° Ð»ÑŽÐ±Ð¾Ð²Ð½Ð¸Ñ† Ð² Ð³Ð¾Ñ€Ð¾Ð´Ðµ Ð˜Ð¿Ð¾. Ð‘Ð¾Ð¸Ñ‚ÑÑ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸ Ñ ÐºÑ€Ð¾ÐºÐ¾Ð´Ð¸Ð»Ð°Ð¼Ð¸. Ð¡Ñ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑÑ Ð¶ÐµÑ€Ñ‚Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð°ÑÑ‚Ð½Ð¾Ð³Ð¾ Ñ‚Ð°Ð½Ñ†Ð° Ð² ÑÐµÐºÑ€ÐµÑ‚Ð½Ð¾Ð¼ Ð±Ð°Ñ€Ðµ ÐšÑƒÐ°Ð»Ð°-Ð›ÑƒÐ¼Ð¿ÑƒÑ€Ð°. Ð—Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑÑ Ñ Ð‘Ñ€ÑŽÑÐ¾Ð¼ Ð›Ð¸ Ð¸ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÑ‚ Ð¿ÐµÑ‰ÐµÑ€Ñƒ Ð¢ÐµÐ¼Ð¿ÑƒÑ€ÑƒÐ½Ð³. Ð˜ Ð¾Ñ‡ÐµÐ½ÑŒ, Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ÑÑ.  Ð—Ð° Ð·Ð½Ð°ÐºÐ¾Ð¼ÑÑ‚Ð²Ð¾ ÑÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¾Ð¹ ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð›ÑŽÐ±Ð¾Ð²Ð¸ (@lyuba_expat) Ð¸ ÐœÐ°Ñ€Ð¸Ð¸ (@travelmusha) Ð¾Ñ‚ Ð²ÑÐµÐ¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ðŸ™‚  Ð—Ð° Ð¿Ñ€Ð¸ÐºÐ¾Ð»Ñ‹ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð²Ñ‹Ð¿ÑƒÑÐºÐ° ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð¾Ð±ÑÑ‚Ð¾ÑÑ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°Ð¼.  #Ð¼Ð°Ð»Ð°Ð¹Ð·Ð¸Ñ #ÐºÑƒÐ°Ð»Ð°Ð»ÑƒÐ¼Ð¿ÑƒÑ€ #Ð¿ÑƒÑ‚ÐµÑˆÐµÑÑ‚Ð²Ð¸Ñ #ÑÐºÐ¾Ð»ÑŒÐºÐ¾ÑÑ‚Ð¾Ð¸Ñ‚Ð¾Ñ‚Ð´Ñ‹Ñ…\n",
    "\n",
    "2: Baikal Mile 2019 - International Festival of speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
